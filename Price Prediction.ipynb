{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Price Prediction.ipynb', 'testset.csv', 'trainset.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(\"trainset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>357.385559</td>\n",
       "      <td>361.151062</td>\n",
       "      <td>355.959839</td>\n",
       "      <td>359.288177</td>\n",
       "      <td>359.288177</td>\n",
       "      <td>5115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>360.122742</td>\n",
       "      <td>363.600128</td>\n",
       "      <td>358.031342</td>\n",
       "      <td>359.496826</td>\n",
       "      <td>359.496826</td>\n",
       "      <td>4666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>362.313507</td>\n",
       "      <td>368.339294</td>\n",
       "      <td>361.488861</td>\n",
       "      <td>366.600616</td>\n",
       "      <td>366.600616</td>\n",
       "      <td>5562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>365.348755</td>\n",
       "      <td>367.301056</td>\n",
       "      <td>362.929504</td>\n",
       "      <td>365.001007</td>\n",
       "      <td>365.001007</td>\n",
       "      <td>3332900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>365.393463</td>\n",
       "      <td>365.771027</td>\n",
       "      <td>359.874359</td>\n",
       "      <td>364.280701</td>\n",
       "      <td>364.280701</td>\n",
       "      <td>3373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>1061.109985</td>\n",
       "      <td>1064.199951</td>\n",
       "      <td>1059.439941</td>\n",
       "      <td>1060.119995</td>\n",
       "      <td>1060.119995</td>\n",
       "      <td>755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>1058.069946</td>\n",
       "      <td>1060.119995</td>\n",
       "      <td>1050.199951</td>\n",
       "      <td>1056.739990</td>\n",
       "      <td>1056.739990</td>\n",
       "      <td>760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>1057.390015</td>\n",
       "      <td>1058.369995</td>\n",
       "      <td>1048.050049</td>\n",
       "      <td>1049.369995</td>\n",
       "      <td>1049.369995</td>\n",
       "      <td>1271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>1051.599976</td>\n",
       "      <td>1054.750000</td>\n",
       "      <td>1044.770020</td>\n",
       "      <td>1048.140015</td>\n",
       "      <td>1048.140015</td>\n",
       "      <td>837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>1046.719971</td>\n",
       "      <td>1049.699951</td>\n",
       "      <td>1044.900024</td>\n",
       "      <td>1046.400024</td>\n",
       "      <td>1046.400024</td>\n",
       "      <td>887500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     2013-01-02   357.385559   361.151062   355.959839   359.288177   \n",
       "1     2013-01-03   360.122742   363.600128   358.031342   359.496826   \n",
       "2     2013-01-04   362.313507   368.339294   361.488861   366.600616   \n",
       "3     2013-01-07   365.348755   367.301056   362.929504   365.001007   \n",
       "4     2013-01-08   365.393463   365.771027   359.874359   364.280701   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1254  2017-12-22  1061.109985  1064.199951  1059.439941  1060.119995   \n",
       "1255  2017-12-26  1058.069946  1060.119995  1050.199951  1056.739990   \n",
       "1256  2017-12-27  1057.390015  1058.369995  1048.050049  1049.369995   \n",
       "1257  2017-12-28  1051.599976  1054.750000  1044.770020  1048.140015   \n",
       "1258  2017-12-29  1046.719971  1049.699951  1044.900024  1046.400024   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0      359.288177  5115500  \n",
       "1      359.496826  4666500  \n",
       "2      366.600616  5562800  \n",
       "3      365.001007  3332900  \n",
       "4      364.280701  3373900  \n",
       "...           ...      ...  \n",
       "1254  1060.119995   755100  \n",
       "1255  1056.739990   760600  \n",
       "1256  1049.369995  1271900  \n",
       "1257  1048.140015   837100  \n",
       "1258  1046.400024   887500  \n",
       "\n",
       "[1259 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 357.385559],\n",
       "       [ 360.122742],\n",
       "       [ 362.313507],\n",
       "       ...,\n",
       "       [1057.390015],\n",
       "       [1051.599976],\n",
       "       [1046.719971]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01011148],\n",
       "       [0.01388614],\n",
       "       [0.01690727],\n",
       "       ...,\n",
       "       [0.97543954],\n",
       "       [0.9674549 ],\n",
       "       [0.96072522]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 60)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0465\n",
      "Epoch 2/100\n",
      "1199/1199 [==============================] - 7s 6ms/step - loss: 0.0053\n",
      "Epoch 3/100\n",
      "1199/1199 [==============================] - 10s 8ms/step - loss: 0.0040\n",
      "Epoch 4/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0036\n",
      "Epoch 5/100\n",
      "1199/1199 [==============================] - 8s 6ms/step - loss: 0.0039\n",
      "Epoch 6/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0036\n",
      "Epoch 7/100\n",
      "1199/1199 [==============================] - 7s 6ms/step - loss: 0.0032\n",
      "Epoch 8/100\n",
      "1199/1199 [==============================] - 7s 6ms/step - loss: 0.0031\n",
      "Epoch 9/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0031\n",
      "Epoch 10/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0034\n",
      "Epoch 11/100\n",
      "1199/1199 [==============================] - 9s 8ms/step - loss: 0.0032\n",
      "Epoch 12/100\n",
      "1199/1199 [==============================] - 8s 6ms/step - loss: 0.0031\n",
      "Epoch 13/100\n",
      "1199/1199 [==============================] - 10s 9ms/step - loss: 0.0029\n",
      "Epoch 14/100\n",
      "1199/1199 [==============================] - 9s 7ms/step - loss: 0.0028\n",
      "Epoch 15/100\n",
      "1199/1199 [==============================] - 10s 8ms/step - loss: 0.0030\n",
      "Epoch 16/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0027\n",
      "Epoch 17/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0031\n",
      "Epoch 18/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0026\n",
      "Epoch 19/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0030\n",
      "Epoch 20/100\n",
      "1199/1199 [==============================] - 8s 7ms/step - loss: 0.0028\n",
      "Epoch 21/100\n",
      "1199/1199 [==============================] - 9s 7ms/step - loss: 0.0028\n",
      "Epoch 22/100\n",
      "1199/1199 [==============================] - 9s 7ms/step - loss: 0.0024\n",
      "Epoch 23/100\n",
      "1199/1199 [==============================] - 9s 7ms/step - loss: 0.0024\n",
      "Epoch 24/100\n",
      "1199/1199 [==============================] - 9s 8ms/step - loss: 0.0023\n",
      "Epoch 25/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0022\n",
      "Epoch 26/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0021\n",
      "Epoch 27/100\n",
      "1199/1199 [==============================] - 11s 9ms/step - loss: 0.0023\n",
      "Epoch 28/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0029\n",
      "Epoch 29/100\n",
      "1199/1199 [==============================] - 11s 9ms/step - loss: 0.0020\n",
      "Epoch 30/100\n",
      "1199/1199 [==============================] - 10s 9ms/step - loss: 0.0020\n",
      "Epoch 31/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0022\n",
      "Epoch 32/100\n",
      "1199/1199 [==============================] - 11s 9ms/step - loss: 0.0022\n",
      "Epoch 33/100\n",
      "1199/1199 [==============================] - 10s 8ms/step - loss: 0.0018\n",
      "Epoch 34/100\n",
      "1199/1199 [==============================] - 14s 11ms/step - loss: 0.0019\n",
      "Epoch 35/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0020\n",
      "Epoch 36/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0019\n",
      "Epoch 37/100\n",
      "1199/1199 [==============================] - 11s 9ms/step - loss: 0.0018\n",
      "Epoch 38/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0020\n",
      "Epoch 39/100\n",
      "1199/1199 [==============================] - 11s 9ms/step - loss: 0.0022\n",
      "Epoch 40/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0022\n",
      "Epoch 41/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0018\n",
      "Epoch 42/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0019\n",
      "Epoch 43/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0017\n",
      "Epoch 44/100\n",
      "1199/1199 [==============================] - 13s 10ms/step - loss: 0.0019\n",
      "Epoch 45/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0019\n",
      "Epoch 46/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0020\n",
      "Epoch 47/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0017\n",
      "Epoch 48/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0019\n",
      "Epoch 49/100\n",
      "1199/1199 [==============================] - 15s 13ms/step - loss: 0.0017\n",
      "Epoch 50/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0017\n",
      "Epoch 51/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0018\n",
      "Epoch 52/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0016\n",
      "Epoch 53/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0016\n",
      "Epoch 54/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0016\n",
      "Epoch 55/100\n",
      "1199/1199 [==============================] - 12s 10ms/step - loss: 0.0017\n",
      "Epoch 56/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0015\n",
      "Epoch 57/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0016\n",
      "Epoch 58/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0016\n",
      "Epoch 59/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0017\n",
      "Epoch 60/100\n",
      "1199/1199 [==============================] - 15s 12ms/step - loss: 0.0017\n",
      "Epoch 61/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0015\n",
      "Epoch 62/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0016\n",
      "Epoch 63/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0017\n",
      "Epoch 64/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0013\n",
      "Epoch 65/100\n",
      "1199/1199 [==============================] - 14s 11ms/step - loss: 0.0013\n",
      "Epoch 66/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0013\n",
      "Epoch 67/100\n",
      "1199/1199 [==============================] - 15s 13ms/step - loss: 0.0014\n",
      "Epoch 68/100\n",
      "1199/1199 [==============================] - 15s 13ms/step - loss: 0.0013\n",
      "Epoch 69/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0015\n",
      "Epoch 70/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0016\n",
      "Epoch 71/100\n",
      "1199/1199 [==============================] - 13s 11ms/step - loss: 0.0014\n",
      "Epoch 72/100\n",
      "  32/1199 [..............................] - ETA: 12s - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.439155). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  64/1199 [>.............................] - ETA: 1:28 - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddarth\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.725562). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0014\n",
      "Epoch 73/100\n",
      "1199/1199 [==============================] - 15s 13ms/step - loss: 0.0013\n",
      "Epoch 74/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0014\n",
      "Epoch 75/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0013\n",
      "Epoch 76/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0016\n",
      "Epoch 77/100\n",
      "1199/1199 [==============================] - 15s 13ms/step - loss: 0.0014\n",
      "Epoch 78/100\n",
      "1199/1199 [==============================] - 14s 12ms/step - loss: 0.0012\n",
      "Epoch 79/100\n",
      "1199/1199 [==============================] - 16s 13ms/step - loss: 0.0015\n",
      "Epoch 80/100\n",
      "1199/1199 [==============================] - 16s 13ms/step - loss: 0.0012\n",
      "Epoch 81/100\n",
      "1199/1199 [==============================] - 18s 15ms/step - loss: 0.0012\n",
      "Epoch 82/100\n",
      "1199/1199 [==============================] - 18s 15ms/step - loss: 0.0012\n",
      "Epoch 83/100\n",
      "1199/1199 [==============================] - 17s 14ms/step - loss: 0.0011\n",
      "Epoch 84/100\n",
      "1199/1199 [==============================] - 20s 17ms/step - loss: 0.0010\n",
      "Epoch 85/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0010\n",
      "Epoch 86/100\n",
      "1199/1199 [==============================] - 21s 18ms/step - loss: 0.0011\n",
      "Epoch 87/100\n",
      "1199/1199 [==============================] - 20s 17ms/step - loss: 0.0010\n",
      "Epoch 88/100\n",
      "1199/1199 [==============================] - 21s 17ms/step - loss: 0.0011\n",
      "Epoch 89/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 9.6882e-04\n",
      "Epoch 90/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0012\n",
      "Epoch 91/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0011\n",
      "Epoch 92/100\n",
      "1199/1199 [==============================] - 16s 13ms/step - loss: 0.0011\n",
      "Epoch 93/100\n",
      "1199/1199 [==============================] - 21s 17ms/step - loss: 0.0011\n",
      "Epoch 94/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0013\n",
      "Epoch 95/100\n",
      "1199/1199 [==============================] - 19s 16ms/step - loss: 0.0012\n",
      "Epoch 96/100\n",
      "1199/1199 [==============================] - 21s 17ms/step - loss: 0.0011\n",
      "Epoch 97/100\n",
      "1199/1199 [==============================] - 21s 17ms/step - loss: 0.0011\n",
      "Epoch 98/100\n",
      "1199/1199 [==============================] - 20s 17ms/step - loss: 0.0010\n",
      "Epoch 99/100\n",
      "1199/1199 [==============================] - 22s 18ms/step - loss: 9.7437e-04\n",
      "Epoch 100/100\n",
      "1199/1199 [==============================] - 25s 21ms/step - loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2315a232f28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test =pd.read_csv(\"testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       357.385559\n",
       "1       360.122742\n",
       "2       362.313507\n",
       "3       365.348755\n",
       "4       365.393463\n",
       "          ...     \n",
       "120    1143.599976\n",
       "121    1128.000000\n",
       "122    1121.339966\n",
       "123    1102.089966\n",
       "124    1120.000000\n",
       "Name: Open, Length: 1384, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 955.48999 ,  966.700012,  980.      ,  980.      ,  973.719971,\n",
       "        987.450012,  992.      ,  992.099976,  990.289978,  991.77002 ,\n",
       "        986.      ,  989.440002,  989.52002 ,  970.      ,  968.369995,\n",
       "        980.      , 1009.190002, 1014.      , 1015.219971, 1017.210022,\n",
       "       1021.76001 , 1022.109985, 1028.98999 , 1027.27002 , 1030.52002 ,\n",
       "       1033.98999 , 1026.459961, 1023.419983, 1022.590027, 1019.210022,\n",
       "       1022.52002 , 1034.01001 , 1020.26001 , 1023.309998, 1035.      ,\n",
       "       1035.869995, 1040.      , 1055.089966, 1042.680054, 1022.369995,\n",
       "       1015.799988, 1012.659973,  995.940002, 1001.5     , 1020.429993,\n",
       "       1037.48999 , 1035.5     , 1039.630005, 1046.119995, 1045.      ,\n",
       "       1054.609985, 1066.079956, 1075.199951, 1071.780029, 1064.949951,\n",
       "       1061.109985, 1058.069946, 1057.390015, 1051.599976, 1046.719971,\n",
       "       1048.339966, 1064.310059, 1088.      , 1094.      , 1102.22998 ,\n",
       "       1109.400024, 1097.099976, 1106.300049, 1102.410034, 1132.51001 ,\n",
       "       1126.219971, 1131.410034, 1131.829956, 1137.48999 , 1159.849976,\n",
       "       1177.329956, 1172.530029, 1175.079956, 1176.47998 , 1167.829956,\n",
       "       1170.569946, 1162.609985, 1122.      , 1090.599976, 1027.180054,\n",
       "       1081.540039, 1055.410034, 1017.25    , 1048.      , 1045.      ,\n",
       "       1048.949951, 1079.069946, 1088.410034, 1090.569946, 1106.469971,\n",
       "       1116.189941, 1112.640015, 1127.800049, 1141.23999 , 1123.030029,\n",
       "       1107.869995, 1053.079956, 1075.140015, 1099.219971, 1089.189941,\n",
       "       1115.319946, 1136.      , 1163.849976, 1170.      , 1145.209961,\n",
       "       1149.959961, 1154.140015, 1120.01001 , 1099.      , 1092.73999 ,\n",
       "       1081.880005, 1047.030029, 1046.      , 1063.      ,  998.      ,\n",
       "       1011.630005, 1022.820007, 1013.909973,  993.409973, 1041.329956,\n",
       "       1020.      , 1016.799988, 1026.439941, 1027.98999 , 1025.040039,\n",
       "       1040.880005, 1037.      , 1051.369995, 1077.430054, 1069.400024,\n",
       "       1082.      , 1077.859985, 1052.      , 1025.52002 , 1029.51001 ,\n",
       "       1046.      , 1030.01001 , 1013.659973, 1028.099976, 1019.      ,\n",
       "       1016.900024, 1049.22998 , 1058.540039, 1058.099976, 1086.030029,\n",
       "       1093.599976, 1100.      , 1090.      , 1077.310059, 1079.890015,\n",
       "       1061.859985, 1074.060059, 1083.560059, 1065.130005, 1079.      ,\n",
       "       1079.02002 , 1064.890015, 1063.030029, 1067.560059, 1099.349976,\n",
       "       1122.329956, 1140.98999 , 1142.170044, 1131.319946, 1118.180054,\n",
       "       1118.599976, 1131.069946, 1141.119995, 1143.849976, 1148.859985,\n",
       "       1143.650024, 1158.5     , 1175.310059, 1174.849976, 1159.140015,\n",
       "       1143.599976, 1128.      , 1121.339966, 1102.089966, 1120.      ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 955.48999 ],\n",
       "       [ 966.700012],\n",
       "       [ 980.      ],\n",
       "       [ 980.      ],\n",
       "       [ 973.719971],\n",
       "       [ 987.450012],\n",
       "       [ 992.      ],\n",
       "       [ 992.099976],\n",
       "       [ 990.289978],\n",
       "       [ 991.77002 ],\n",
       "       [ 986.      ],\n",
       "       [ 989.440002],\n",
       "       [ 989.52002 ],\n",
       "       [ 970.      ],\n",
       "       [ 968.369995],\n",
       "       [ 980.      ],\n",
       "       [1009.190002],\n",
       "       [1014.      ],\n",
       "       [1015.219971],\n",
       "       [1017.210022],\n",
       "       [1021.76001 ],\n",
       "       [1022.109985],\n",
       "       [1028.98999 ],\n",
       "       [1027.27002 ],\n",
       "       [1030.52002 ],\n",
       "       [1033.98999 ],\n",
       "       [1026.459961],\n",
       "       [1023.419983],\n",
       "       [1022.590027],\n",
       "       [1019.210022],\n",
       "       [1022.52002 ],\n",
       "       [1034.01001 ],\n",
       "       [1020.26001 ],\n",
       "       [1023.309998],\n",
       "       [1035.      ],\n",
       "       [1035.869995],\n",
       "       [1040.      ],\n",
       "       [1055.089966],\n",
       "       [1042.680054],\n",
       "       [1022.369995],\n",
       "       [1015.799988],\n",
       "       [1012.659973],\n",
       "       [ 995.940002],\n",
       "       [1001.5     ],\n",
       "       [1020.429993],\n",
       "       [1037.48999 ],\n",
       "       [1035.5     ],\n",
       "       [1039.630005],\n",
       "       [1046.119995],\n",
       "       [1045.      ],\n",
       "       [1054.609985],\n",
       "       [1066.079956],\n",
       "       [1075.199951],\n",
       "       [1071.780029],\n",
       "       [1064.949951],\n",
       "       [1061.109985],\n",
       "       [1058.069946],\n",
       "       [1057.390015],\n",
       "       [1051.599976],\n",
       "       [1046.719971],\n",
       "       [1048.339966],\n",
       "       [1064.310059],\n",
       "       [1088.      ],\n",
       "       [1094.      ],\n",
       "       [1102.22998 ],\n",
       "       [1109.400024],\n",
       "       [1097.099976],\n",
       "       [1106.300049],\n",
       "       [1102.410034],\n",
       "       [1132.51001 ],\n",
       "       [1126.219971],\n",
       "       [1131.410034],\n",
       "       [1131.829956],\n",
       "       [1137.48999 ],\n",
       "       [1159.849976],\n",
       "       [1177.329956],\n",
       "       [1172.530029],\n",
       "       [1175.079956],\n",
       "       [1176.47998 ],\n",
       "       [1167.829956],\n",
       "       [1170.569946],\n",
       "       [1162.609985],\n",
       "       [1122.      ],\n",
       "       [1090.599976],\n",
       "       [1027.180054],\n",
       "       [1081.540039],\n",
       "       [1055.410034],\n",
       "       [1017.25    ],\n",
       "       [1048.      ],\n",
       "       [1045.      ],\n",
       "       [1048.949951],\n",
       "       [1079.069946],\n",
       "       [1088.410034],\n",
       "       [1090.569946],\n",
       "       [1106.469971],\n",
       "       [1116.189941],\n",
       "       [1112.640015],\n",
       "       [1127.800049],\n",
       "       [1141.23999 ],\n",
       "       [1123.030029],\n",
       "       [1107.869995],\n",
       "       [1053.079956],\n",
       "       [1075.140015],\n",
       "       [1099.219971],\n",
       "       [1089.189941],\n",
       "       [1115.319946],\n",
       "       [1136.      ],\n",
       "       [1163.849976],\n",
       "       [1170.      ],\n",
       "       [1145.209961],\n",
       "       [1149.959961],\n",
       "       [1154.140015],\n",
       "       [1120.01001 ],\n",
       "       [1099.      ],\n",
       "       [1092.73999 ],\n",
       "       [1081.880005],\n",
       "       [1047.030029],\n",
       "       [1046.      ],\n",
       "       [1063.      ],\n",
       "       [ 998.      ],\n",
       "       [1011.630005],\n",
       "       [1022.820007],\n",
       "       [1013.909973],\n",
       "       [ 993.409973],\n",
       "       [1041.329956],\n",
       "       [1020.      ],\n",
       "       [1016.799988],\n",
       "       [1026.439941],\n",
       "       [1027.98999 ],\n",
       "       [1025.040039],\n",
       "       [1040.880005],\n",
       "       [1037.      ],\n",
       "       [1051.369995],\n",
       "       [1077.430054],\n",
       "       [1069.400024],\n",
       "       [1082.      ],\n",
       "       [1077.859985],\n",
       "       [1052.      ],\n",
       "       [1025.52002 ],\n",
       "       [1029.51001 ],\n",
       "       [1046.      ],\n",
       "       [1030.01001 ],\n",
       "       [1013.659973],\n",
       "       [1028.099976],\n",
       "       [1019.      ],\n",
       "       [1016.900024],\n",
       "       [1049.22998 ],\n",
       "       [1058.540039],\n",
       "       [1058.099976],\n",
       "       [1086.030029],\n",
       "       [1093.599976],\n",
       "       [1100.      ],\n",
       "       [1090.      ],\n",
       "       [1077.310059],\n",
       "       [1079.890015],\n",
       "       [1061.859985],\n",
       "       [1074.060059],\n",
       "       [1083.560059],\n",
       "       [1065.130005],\n",
       "       [1079.      ],\n",
       "       [1079.02002 ],\n",
       "       [1064.890015],\n",
       "       [1063.030029],\n",
       "       [1067.560059],\n",
       "       [1099.349976],\n",
       "       [1122.329956],\n",
       "       [1140.98999 ],\n",
       "       [1142.170044],\n",
       "       [1131.319946],\n",
       "       [1118.180054],\n",
       "       [1118.599976],\n",
       "       [1131.069946],\n",
       "       [1141.119995],\n",
       "       [1143.849976],\n",
       "       [1148.859985],\n",
       "       [1143.650024],\n",
       "       [1158.5     ],\n",
       "       [1175.310059],\n",
       "       [1174.849976],\n",
       "       [1159.140015],\n",
       "       [1143.599976],\n",
       "       [1128.      ],\n",
       "       [1121.339966],\n",
       "       [1102.089966],\n",
       "       [1120.      ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = sc.transform(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
